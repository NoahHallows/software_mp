import sys
from PySide6.QtWidgets import QApplication, QDialog, QDialogButtonBox, QLineEdit, QVBoxLayout, QFileDialog, QProgressBar, QRadioButton, QPushButton, QLabel, QGridLayout, QListWidget, QMessageBox
from PySide6.QtCore import Slot
from PySide6.QtGui import QPixmap
import re
import cv2 as cv
import os
from time import sleep
from multiprocessing import cpu_count, Queue, Pool, Value, Process, Event, freeze_support
import pathlib
import face_recognition
import concurrent.futures
progress <- Value('i', 0)
images_to_search <- []
event <- Event()
data_queue <- Queue()

CLASS Window(QDialog):
    @Slot()
    FUNCTION radio(self):
        button <-  sender()
         action <- button.option
    ENDFUNCTION

    FUNCTION end_screen(self, results):
         close()
        end_grid <- QGridLayout()
        FOR image_name IN results:
            image <- cv.imread(image_name)
            height, width, channels <- image.shape
            scale_factor <- 200/height
            new_width <- int(round(scale_factor*width, 0))
            resized_image <- cv.resize(image, (new_width, 200), interpolation=cv.INTER_AREA)
            imgbytes <- cv.imencode(".png", resized_image)[1].tobytes()
            image_display <-  QLabel(self)
            pixmap <- QPixmap(resized_image)
            image_display.setPixmap(pixmap)
            end_grid.addWidget(image_display, 0,0)
        ENDFOR
    ENDFUNCTION

    @Slot()
    FUNCTION select_target_face(self):
        target_face_location_untrimmed <- QFileDialog.getOpenFileName(self, ("Open image"), "", ("Image (*.png *.jpg *.bmp)"))
        IF target_face_location_untrimmed:
             target_image_text_box.clear()
             target_face_location <- Extract from 2nd character until character == "'" from target_face_location_untrimmed into target_face_location
             target_image_text_box.setText( target_face_location)
        ENDIF
    ENDFUNCTION

    FUNCTION progress_bar_update(self, images_to_search):
        percentage <- 0
        WHILE percentage <= 100:
            percentage <- progress.value * (100/len(images_to_search))
             progress_bar.setValue(percentage)
            sleep(0.5)
        ENDWHILE
    ENDFUNCTION

    @Slot()
    FUNCTION accept(self):
        IF images_to_search_location != '' AND  action != 0 AND  target_face_location != '':
            progress_worker <- concurrent.futures.ThreadPoolExecutor(max_workers=1)
            progress_worker.submit( progress_bar_update,  images_to_search)
            data_queue.put([ action,  target_face_location,  images_to_search,  overlay_image_location])
            event.set()
        ELSE:
            msgBox <- QMessageBox()
            msgBox.exec()
        ENDIF
    ENDFUNCTION

    @Slot()
    FUNCTION cancel(self):
         close()
    ENDFUNCTION

    FUNCTION __init__(self):
         overlay_image_location <- None
        super().__init__(parent=None)
         setWindowTitle("Face removal tool v0.8")
        dialogLayout <- QVBoxLayout()
        gridLayout <- QGridLayout()
        target_image_button <- QPushButton("Browse")
         target_image_text_box <- QLineEdit()
         target_image_text_box.setReadOnly(True)
        gridLayout.addWidget(QLabel("Select the image containing the face to search for:"), 0, 0)
        gridLayout.addWidget( target_image_text_box, 0, 1)
        gridLayout.addWidget(target_image_button, 0, 2)
        target_image_button.clicked.connect( select_target_face)
        select_image_directory_button <- QPushButton("Browse")
        select_image_directory_text_box <- QLineEdit()
        select_image_directory_text_box.setReadOnly(True)
        gridLayout.addWidget(QLabel("Select the directory contining images to search:"), 1, 0)
        gridLayout.addWidget( select_image_directory_text_box, 1, 1)
        gridLayout.addWidget(select_image_directory_button, 1, 2)
        select_image_directory_button.clicked.connect( select_image_directory)
        image_list_box <- QListWidget()
        gridLayout.addWidget( image_list_box, 2, 0, 1, 2)
        blur_button <- QRadioButton("Blur matching faces", self)
        blur_button.option <- 1
        replace_button <- QRadioButton("Replace matching faces", self)
        replace_button.option <- 2
        delete_button <- QRadioButton("Delete images containg matching faces", self)
        delete_button.option <- 3
        gridLayout.addWidget(QLabel("What should the program do to matching faces:"), 3, 0, 1, 2)
        gridLayout.addWidget(blur_button, 4, 0)
        gridLayout.addWidget(replace_button, 5, 0)
        gridLayout.addWidget(delete_button, 6, 0)
        blur_button.clicked.connect( radio)
        replace_button.clicked.connect( radio)
        delete_button.clicked.connect( radio)
        select_overlay_button <- QPushButton("Browse")
        select_overlay_text_box <- QLineEdit()
        select_overlay_text_box.setReadOnly(True)
        gridLayout.addWidget(QLabel("Select the overlay image:"), 7, 0)
        gridLayout.addWidget( select_overlay_text_box, 7, 1)
        gridLayout.addWidget(select_overlay_button, 7, 2)
        select_overlay_button.clicked.connect( select_overlay_image)
        dialogLayout.addLayout(gridLayout)
        progress_bar <- QProgressBar()
        dialogLayout.addWidget( progress_bar)
        standard_buttons <- QDialogButtonBox(QDialogButtonBox.Ok
                             = QDialogButtonBox.Cancel)
        dialogLayout.addWidget( standard_buttons)
        standard_buttons.accepted.connect( accept)
        standard_buttons.rejected.connect( reject)
        setLayout(dialogLayout)
    ENDFUNCTION

    @Slot()
    FUNCTION select_overlay_image(self):
        overlay_image_location_untrimmed <- QFileDialog.getOpenFileName(self, ("Open image"), "", ("Image (*.png *.jpg *.bmp)"))
        IF overlay_image_location_untrimmed:
             select_overlay_text_box.clear()
            Extract from 2nd character until character == "'" from overlay_image_location_untrimmed into overlay_image_location
             select_overlay_text_box.setText(overlay_image_location)
        ENDIF
    ENDFUNCTION

    @Slot()
    FUNCTION select_image_directory(self):
         images_to_search_location <- QFileDialog.getExistingDirectory(self, ("Open folder"))
        IF  images_to_search_location:
             select_image_directory_text_box.clear()
             select_image_directory_text_box.setText(str( images_to_search_location))
             images_to_search <- get_files( images_to_search_location)
            FOR image IN images_to_search:
                 image_list_box.addItem(image)
            ENDFOR
        ENDIF
    ENDFUNCTION

ENDCLASS

CLASS backend:
    FUNCTION __init__(self):
        app <- QApplication([])
        window <- Window()
        event.wait()
        input_data <- data_queue.get()
        action <- input_data[0]
        target_face_location <- input_data[1]
        images_to_search <- input_data[2]
        overlay_image_location <- input_data[3]
        start( images_to_search,  action)
    ENDFUNCTION

    FUNCTION start(self, images_to_search, action):
        progress.value <- 0
        TRY:
            face_to_search_for <- face_recognition.load_image_file( target_face_location)
             face_to_search_for_encoding <- face_recognition.face_encodings(face_to_search_for)[0]
        EXCEPT Exception as e:
            OUTPUT f"Error {e}"
            msgBox <- QMessageBox()
            msgBox.setText(f"No face found in image containing target face\n{e}")
            msgBox.exec()
        ENDTRY
        IF action = 2:
             overlay <- cv.imread( overlay_image_location)
        ENDIF
        WITH Pool(processes=cpu_count()) as pool:
            results <- pool.map( face_recog, images_to_search)
        results <- [item FOR item in results IF item is not None]
        msgBox <- QMessageBox()
        msgBox.setText("The images have been searched")
        msgBox.exec()
    ENDFUNCTION

    FUNCTION face_recog(self, image_name):
        TRY:
            image <- face_recognition.load_image_file(image_name)
            image_encodings <- face_recognition.face_encodings(image)
            IF image_encodings:
                image_encoding <- image_encodings[0]
                results <- face_recognition.compare_faces([ face_to_search_for_encoding], image_encoding)
                image_bgr <- cv.cvtColor(image, cv.COLOR_RGB2BGR)
                IF results[0]:
                    face_locations <- face_recognition.face_locations(image)
                    FOR face_location in face_locations:
                        face_encoding <- face_recognition.face_encodings(image, [face_location])[0]
                        match <- face_recognition.compare_faces([ face_to_search_for_encoding], face_encoding)
                        IF match[0]:
                            IF action = 1:
                                new_image <- editing_image.blur(image_bgr, face_location, 1)
                            ELSEIF action = 2:
                                new_image <- editing_image.replace(image_bgr,  overlay, face_location, 1)
                            ELSEIF action = 3:
                                os.remove(image_name)
                            ENDIF
                            cv.imwrite(image_name, new_image)
                            progress.value += 1
                        ENDIF
                        RETURN image_name
                    ENDFOR
                ELSE:
                    progress.value += 1
                    RETURN f"Image {image_name} doesn't match"
                ENDIF
            ELSE:
                progress.value += 1
                RETURN f"No faces found in image {image_name}"
            ENDIF
        EXCEPT Exception as e:
            progress.value += 1
            RETURN f"An error occurred with image {image_name}: {e}"
        ENDTRY
    ENDFUNCTION

ENDCLASS

FUNCTION get_files(images_to_search_location):
    FOR file in pathlib.Path(images_to_search_location).rglob("*.jpg"):
        images_to_search.append(str(file))
    ENDFOR
    FOR file in pathlib.Path(images_to_search_location).rglob("*.JPG"):
        images_to_search.append(str(file))
    ENDFOR
    FOR file in pathlib.Path(images_to_search_location).rglob("*.png"):
        images_to_search.append(str(file))
    ENDFOR
    RETURN list(images_to_search)
ENDFUNCTION

CLASS editing_image():
    FUNCTION blur(image_bgr, target_face_location, scale_factor):
        top, right, bottom, left <- target_face_location
        top <- int(top / scale_factor)
        right <- int(right / scale_factor)
        bottom <- int(bottom / scale_factor)
        left <- int(left / scale_factor)
        width <- right - left
        height <- bottom - top
        top <- max(top - 10, 0)
        right <- min(right + 10, image_bgr.shape[1])
        bottom <- min(bottom + 10, image_bgr.shape[0])
        left <- max(left - 10, 0)
        face_roi <- image_bgr[top:bottom, left:right]
        blurred_face <- cv.GaussianBlur(face_roi, (999, 999), 0)
        image_bgr[top:bottom, left:right] <- blurred_face
        RETURN image_bgr
    ENDFUNCTION

    FUNCTION replace(background, overlay, target_face_location, scale_factor):
        top, right, bottom, left <- target_face_location
        top <- int(top / scale_factor)
        right <- int(right / scale_factor)
        bottom <- int(bottom / scale_factor)
        left <- int(left / scale_factor)
        width <- right - left
        height <- botton - top
        top <- max(0, top - 10)
        bottom <- min(background.shape[0], bottom + 10)
        left <- max(0, left - 10)
        right <- min(background.shape[1], right + 10)
        width <- width + 20
        height <- height + 20
        IF width > 0 AND height > 0:
            overlay_resized <- cv.resize(overlay, (width, height))
        ELSE:
            OUTPUT f"Invalid size for resize operation: width={width}, height={height}"
            RETURN background
	ENDIF
        IF overlay_resized.shape[2] = 4:
            overlay_color <- overlay_resized[:, :, :3]
            alpha_mask <- overlay_resized[:, :, 3] / 255.0
            roi <- background[top:bottom, left:right]
            roi <- cv.addWeighted(overlay_color, alpha_mask, roi, 1 - alpha_mask, 0, roi)
            background[top:bottom, left:right] <- roi
        ELSE:
            background[top:bottom, left:right] <- overlay_resized
        ENDIF
        RETURN background
    ENDFUNCTION

ENDCLASS

FUNCTION ui_start():
    app <- QApplication([])
    window <- Window()
    window.show()
    sys.exit(app.exec())
ENDFUNCTION

FUNCTION main():
    freeze_support()
    frontend_thread <- Process(target=ui_start)
    backend_thread <- Process(target=backend)
    frontend_thread.start()
    backend_thread.start()
    frontend_thread.join()
    backend_thread.join()
ENDFUNCTION

IF __name__ = "__main__":
    main()
ENDIF
